{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes\n",
    "\n",
    "In this lesson, we will introduce pandas *dataframes*. Dataframes represent tabular, 2-dimensional data, and provide a number of facilities for manipulating and transforming the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Example Dataframe \n",
    "\n",
    "The code below will create a data frame that represents grades for multiple students. We pass a dictionary where the keys will correspond to the names of the columns, and the values associated with those keys will make up the data. We will talk in more detail about different ways to create a dataframe in a coming lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "students = ['Sally', 'Jane', 'Suzie', 'Billy', 'Ada', 'John', 'Thomas',\n",
    "            'Marie', 'Albert', 'Richard', 'Isaac', 'Alan']\n",
    "\n",
    "# randomly generate scores for each student for each subject\n",
    "# note that all the values need to have the same length here\n",
    "math_grades = np.random.randint(low=60, high=100, size=len(students))\n",
    "english_grades = np.random.randint(low=60, high=100, size=len(students))\n",
    "reading_grades = np.random.randint(low=60, high=100, size=len(students))\n",
    "\n",
    "df = pd.DataFrame({'name': students,\n",
    "                   'math': math_grades,\n",
    "                   'english': english_grades,\n",
    "                   'reading': reading_grades})\n",
    "\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we might expect, the dataframe stored in the `df` variable has a type of `DataFrame`.\n",
    "\n",
    "Dataframes also have a nice, printed representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, if we are within a jupyter notebook (or the Codeup curriculum), we can get a nice html representation of a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing Dataframes\n",
    "\n",
    "The `.info` prints out some useful information about the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.describe` method gives a quick summary of the numerical values in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Attributes\n",
    "\n",
    "Dataframes have several attributes that are important to be familiar with:\n",
    "\n",
    "- `dtypes`: the data type of each column\n",
    "- `shape`: the number of rows and columns in the dataframe\n",
    "- `columns`: the list of column names\n",
    "- `index`: the labels for each row (usually an autogenerated number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.columns` attribute can be assigned to in order to change the name of the columns in the data frame. For example, if we wanted to uppercase every column name, we could do so like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [col.upper() for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we'll reset the column names back to what they used to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [col.lower() for col in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting Dataframes\n",
    "\n",
    "There are a number of ways we can access certain subsets, i.e. either a restricted number of rows, columns, or both, of our dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Individual Columns\n",
    "\n",
    "Each column in a dataframe is a `Series` that we discussed in the previous lesson. These values can be accessed in one of two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using . notation\n",
    "df.math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using square brackets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the first way is preferred, but the second way is required if the name of the column is not a valid python identifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Multiple Columns\n",
    "\n",
    "We can see multiple columns in the dataframe by subsetting the dataframe with a list of strings. The following two code samples are functionally equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['name', 'math']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['name', 'math']\n",
    "df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Row Subsets\n",
    "\n",
    "Pandas provides several convenience methods for quickly looking at several rows in a dataframe:\n",
    "\n",
    "- `.head`: for the first n (default 5) rows\n",
    "- `.tail`: for the last n (default 5) rows\n",
    "- `.sample`: for a random sample of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like numpy arrays and pandas `Series`, pandas dataframes can also be indexed into with a boolean series.\n",
    "\n",
    "For example, suppose we wanted to find the observations in our dataframe where the math grade is below an 80. We know that we can produce a boolean series of values using a vectorized comparison operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.math < 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use that series to index into our dataframe to find the entire row where our condition is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.math < 80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping and Renaming Columns\n",
    "\n",
    "We can drop columns with the `.drop` method, and, similarly, rename them with `.rename`.\n",
    "\n",
    "For both methods (and many other methods within pandas), the original dataframe **will not be changed**. Instead, the methods will produce a new dataframe. This is similar to the behavior we have seen with, for example, string methods. The exception to this is that most pandas methods will accept an optional keyword argument of `inplace` (defaults to `False`) to determine whether to mutate the original value.\n",
    "\n",
    "Let's take a look at a couple of examples of `.drop` and `.rename`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop english and reading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename 'name' column to 'student'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `columns` keyword argument with both `.drop` and `.rename`. We'll pass a list of column names we want to remove to `.drop`, and a dictionary of columns to rename to `.rename`. Within the passed dictionary, the keys will be the old column names, and the values are the new column names.\n",
    "\n",
    "Notice that, after both of these operations, the original variable is unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because these methods each return a dataframe, we can *chain* them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['english', 'reading']).rename(columns={'name': 'student'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Dataframes\n",
    "\n",
    "We can use the `.sort_values` method to sort a dataframe by any given criteria. For example, we can sort by the english grade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sort in descending order by providing the a keyword arugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='english', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining Dataframe Methods\n",
    "\n",
    "Because most dataframe methods return another dataframe, it is common to see them *chained* together.\n",
    "\n",
    "For example, we could use method chaining to find the name of the student with the *lowest* english grade above a 90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.english > 90].sort_values(by='english').head(1).name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the above expression piece by piece:\n",
    "\n",
    "1. `df`: our initial variable that holds our dataframe\n",
    "1. `[df.english > 90]`: here we subset the datframe to find just the rows where the english grade is greater than 90\n",
    "1. `.sort_values(by='english')`: now we take the remaining rows and sort them by the english grade\n",
    "1. `.head(1)`: take just the first record. Because we sorted previously, this will give us the student with lowest english grade\n",
    "1. `.name`: extract just the `name` part of the record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "- [pandas documentation: `DataFrame`s](https://pandas.pydata.org/pandas-docs/stable/getting_started/dsintro.html#dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Do your work for this exercise in a python script or a jupyter notebook with the name `dataframes.py` or `dataframes.ipynb`.\n",
    "\n",
    "For several of the following exercises, you'll need to load several datasets using the `pydataset` library. (If you get an error when trying to run the import below, use `pip` to install the `pydataset` package.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the instructions say to load a dataset, you can pass the name of the dataset as a string to the `data` function to load the dataset. You can also view the documentation for the data set by passing the `show_doc` keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data('mpg', show_doc=True) # view the documentation for the dataset\n",
    "mpg = data('mpg') # load the dataset and store it in a variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the datasets loaded from the `pydataset` library will be pandas dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Copy the code from the lesson to create a dataframe full of student grades.\n",
    "\n",
    "    1. Create a column named `passing_english` that indicates whether each student has a passing grade in english.\n",
    "    1. Sort the english grades by the `passing_english` column. How are duplicates handled?\n",
    "    1. Sort the english grades first by `passing_english` and then by student name. All the students that are failing english should be first, and within the students that are failing english they should be ordered alphabetically. The same should be true for the students passing english. (Hint: you can pass a list to the `.sort_values` method)\n",
    "    1. Sort the english grades first by `passing_english`, and then by the actual english grade, similar to how we did in the last step.\n",
    "    1. Calculate each students overall grade and add it as a column on the dataframe. The overall grade is the average of the math, english, and reading grades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Load the `mpg` dataset. Read the documentation for the dataset and use it for the following questions:\n",
    "\n",
    "    - How many rows and columns are there?\n",
    "    - What are the data types of each column?\n",
    "    - Summarize the dataframe with `.info` and `.describe`\n",
    "    - Rename the `cty` column to `city`.\n",
    "    - Rename the `hwy` column to `highway`.\n",
    "    - Do any cars have better city mileage than highway mileage?\n",
    "    - Create a column named `mileage_difference` this column should contain the difference between highway and city mileage for each car.\n",
    "    - Which car (or cars) has the highest mileage difference?\n",
    "    - Which compact class car has the lowest highway mileage? The best?\n",
    "    - Create a column named `average_mileage` that is the mean of the city and highway mileage.\n",
    "    - Which dodge car has the best average mileage? The worst?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the `Mammals` dataset. Read the documentation for it, and use the data to answer these questions:\n",
    "\n",
    "    - How many rows and columns are there?\n",
    "    - What are the data types?\n",
    "    - Summarize the dataframe with `.info` and `.describe`\n",
    "    - What is the the weight of the fastest animal?\n",
    "    - What is the overal percentage of specials?\n",
    "    - How many animals are hoppers that are above the median speed? What percentage is this?\n",
    "    \n",
    "    \n",
    "### ** Awesome Bonus **\n",
    "For much more practice with pandas, Go to `https://github.com/guipsamora/pandas_exercises` and clone the repo down to your laptop. To clone a repository:\n",
    "- Copy the SSH address of the repository\n",
    "- `cd ~/codeup-data-science`\n",
    "- Then type `git clone git@github.com:guipsamora/pandas_exercises.git`\n",
    "- Now do `cd pandas_exercises` on your terminal.\n",
    "- Type `git remote remove origin`, so you won't accidentally try to push your work to guipsamora's repo.\n",
    "\n",
    "Congratulations! You have cloned guipsamora's pandas exercises to your computer. Now you need to make a new, blank, repository on GitHub.\n",
    "\n",
    "- Go to `https://github.com/new` to make a new repo. Name it `pandas_exercises`.\n",
    "- DO NOT check any check boxes. We need a blank, empty repo.\n",
    "- Finally, follow the directions to \"push an existing repository from the command line\" so that you can push up your changes to your own account. \n",
    "- Now do your own work, add it, commit it, and push it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
